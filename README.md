# iit-indore-winter-internship
project on computer vision image to image translation using advance GANs
Frequency-Aware Semantic Consistency for Unpaired Image-to-Image Translation
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red.svg)
![CUDA](https://img.shields.io/badge/CUDA-Enabled-green.svg)
![GAN](https://img.shields.io/badge/Model-GAN-orange.svg)
![ViT](https://img.shields.io/badge/Backbone-ViT-purple.svg)
![CLIP](https://img.shields.io/badge/CLIP-OpenAI-black.svg)
![DINO](https://img.shields.io/badge/DINO-ViT-blueviolet.svg)
![Wavelet](https://img.shields.io/badge/Frequency-Wavelet%20DWT-teal.svg)
![License](https://img.shields.io/badge/License-Academic%20Use-lightgrey.svg)
![Status](https://img.shields.io/badge/Status-Completed-success.svg)


This repository contains the implementation of a Frequency-Aware GAN framework for unpaired image-to-image translation, inspired by the research paper:

â€œTowards Semantically Continuous Unpaired Image-to-Image Translation via Margin Adaptive Contrastive Learning and Wavelet Transformâ€
Expert Systems With Applications, Elsevier (2024)

The project focuses on semantic consistency preservation, frequency-domain modeling, and contrastive learning for high-quality unpaired image translation.

ğŸ” Overview

Unpaired image-to-image translation aims to learn a mapping between two visual domains without paired training data.
Traditional GAN-based approaches often suffer from:

Semantic distortions

Texture inconsistency

Mode collapse

This work addresses these issues by integrating:

Wavelet-based frequency decomposition

Margin Adaptive Contrastive Learning (MACL)

Frequency Feature Transform Normalization (FFTN)

CLIP and DINO-based semantic guidance

ğŸ§  Key Contributions

âœ… Frequency-aware generator using Haar Wavelet Transform

âœ… Adaptive Frequency Fusion (AFF) for low/high-frequency integration

âœ… FFTN blocks for frequency-guided feature normalization

âœ… CLIP-based patch-level contrastive loss (MACL)

âœ… DINO-ViT global semantic consistency loss

âœ… Stable training with PatchGAN discriminator

âœ… Automatic checkpoint resuming support

ğŸ—ï¸ Architecture
Generator (MACL Generator)

Encoderâ€“Decoder CNN

Haar DWT/IDWT for frequency decomposition

FFTN-based residual blocks

Adaptive Frequency Fusion (AFF)

Discriminator

PatchGAN with Spectral Normalization

Semantic Guidance

CLIP ViT-B/32 â†’ patch-level contrastive features

DINO ViT-Base â†’ global semantic consistency

ğŸ“‚ Project Structure
macl_net/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ discriminator.py
â”‚   â”œâ”€â”€ resblocks.py
â”‚   â”œâ”€â”€ fftn.py
â”‚   â”œâ”€â”€ aff.py
â”‚   â”œâ”€â”€ clip_encoder.py
â”‚   â””â”€â”€ dino_encoder.py
â”‚
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ gan_loss.py
â”‚   â”œâ”€â”€ macl_loss.py
â”‚   â””â”€â”€ global_vit_loss.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ wavelet.py
â”‚   â””â”€â”€ image_utils.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ unpaired_dataset.py
â”‚
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ outputs/
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ plot_results.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ—‚ï¸ Dataset

We use the Horse â†” Zebra unpaired dataset, originally introduced with CycleGAN.

Domain A: Horse images

Domain B: Zebra images

No paired samples required

Ensure dataset structure:

dataset/
â”œâ”€â”€ horse/
â””â”€â”€ zebra/

âš™ï¸ Installation
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/macl-net.git
cd macl-net

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


âš ï¸ CUDA-enabled PyTorch is strongly recommended.

ğŸš€ Training
Start Training (with Auto-Resume)
python train.py


Automatically resumes from latest checkpoint

Supports GPU acceleration

Saves outputs and checkpoints periodically

Force Fresh Training from Epoch 0
rm -rf checkpoints/*
python train.py

ğŸ” Checkpoint Resume Logic

Automatically loads latest macl_epoch_*.pth

Training continues from the last completed epoch

Safe to interrupt and resume anytime

ğŸ“Š Evaluation & Visualization
Plot Training Curves
python plot_results.py


Generates:

Generator loss

Discriminator loss

MACL loss

Global semantic loss

Output Samples

Generated images are saved in:

outputs/fake_<step>.png

ğŸ–¼ï¸ Results

Progressive improvement in zebra texture patterns

Strong semantic alignment with input horse structure

Reduced distortion compared to baseline GANs

Stable convergence with frequency-aware learning

ğŸ“– Reference

If you use this work, please cite:

H. Zhang, Y.-J. Yang, and W. Zeng,
"Towards Semantically Continuous Unpaired Image-to-Image Translation
via Margin Adaptive Contrastive Learning and Wavelet Transform,"
Expert Systems With Applications, 2024.

ğŸ™ Acknowledgements

This work was carried out under the guidance of
Prof. Surya Prakash, IIT Indore

Special thanks to Mr. Prasant Phatak (PhD Scholar)
for technical mentoring and research guidance.

ğŸ“œ License

This project is intended for research and academic use only.

âœ¨ Author

Shivansh Gupta
B.Tech (AI & Data Science)
Dual Degree, IIT Madras (Data Science)
Intern, IIT Indore
